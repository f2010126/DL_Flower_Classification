{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLComp.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOptGYzRV1EcpEmZUEZW6fq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/f2010126/CodeworkWS2021/blob/main/DLComp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPmhED-bFIHh"
      },
      "source": [
        "Add Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9Z4_o3gFLsL",
        "outputId": "6f3da98c-5c72-4987-d8a6-abff03e97e26"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pm-fPrvH4S91"
      },
      "source": [
        "Code from evaluate.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S3lB3hny_Kr"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "# commented for notebook\n",
        "# from src.cnn import *\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class AverageMeter(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.cnt = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.sum += val * n\n",
        "        self.cnt += n\n",
        "        self.avg = self.sum / self.cnt\n",
        "\n",
        "def accuracy(logits, labels):\n",
        "    preds = torch.argmax(logits, axis=1)\n",
        "    return torch.sum(preds == labels) / len(labels)\n",
        "\n",
        "def eval_fn(model, loader, device, train=False):\n",
        "    \"\"\"\n",
        "    Evaluation method\n",
        "    :param model: model to evaluate\n",
        "    :param loader: data loader for either training or testing set\n",
        "    :param device: torch device\n",
        "    :param train: boolean to indicate if training or test set is used\n",
        "    :return: accuracy on the data\n",
        "    \"\"\"\n",
        "    score = AverageMeter()\n",
        "    model.eval()\n",
        "\n",
        "    t = tqdm(loader)\n",
        "    with torch.no_grad():  # no gradient needed\n",
        "        for images, labels in t:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            acc = accuracy(outputs, labels)\n",
        "            score.update(acc.item(), images.size(0))\n",
        "\n",
        "            t.set_description('(=> Test) Score: {:.4f}'.format(score.avg))\n",
        "\n",
        "    return score.avg\n",
        "\n",
        "def eval_model(model, saved_model_file, test_data_dir, data_augmentations):\n",
        "    model = model.to(device)\n",
        "    model.load_state_dict(torch.load(os.path.join(os.getcwd(), 'models', saved_model_file)))\n",
        "    data = ImageFolder(test_data_dir, transform=data_augmentations)\n",
        "\n",
        "    test_loader = DataLoader(dataset=data,\n",
        "                             batch_size=128,\n",
        "                             shuffle=False)\n",
        "\n",
        "    score = eval_fn(model, test_loader, device, train=False)\n",
        "\n",
        "    print('Avg accuracy:', str(score*100) + '%')\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3fpLM3r41gu"
      },
      "source": [
        "cnn.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "856zY24U4gtS"
      },
      "source": [
        "\"\"\" File with CNN models. Add your custom CNN model here. \"\"\"\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class SampleModel(nn.Module):\n",
        "    \"\"\"\n",
        "    A sample PyTorch CNN model\n",
        "    \"\"\"\n",
        "    def __init__(self, input_shape=(3, 64, 64), num_classes=10):\n",
        "        super(SampleModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=input_shape[0], out_channels=10, kernel_size=(3,3), padding=(1,1))\n",
        "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=(3,3), padding=(1,1))\n",
        "        self.pool = nn.MaxPool2d(3, stride=2)\n",
        "        # The input features for the linear layer depends on the size of the input to the convolutional layer\n",
        "        # So if you resize your image in data augmentations, you'll have to tweak this too.\n",
        "        self.fc1 = nn.Linear(in_features=4500, out_features=32)\n",
        "        self.fc2 = nn.Linear(in_features=32, out_features=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5yLlG8x5Qho"
      },
      "source": [
        "data_augmentations.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwOpmzCE40MX"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "\n",
        "resize_to_64x64 = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "resize_and_colour_jitter = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.ToTensor()\n",
        "])\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2N3TSeE5jYR"
      },
      "source": [
        "main.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "PDsj41Ah5b3G",
        "outputId": "0bde700a-59da-48bd-b22d-25866d4fa8ec"
      },
      "source": [
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
        "from torchsummary import summary\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# commented for notebook\n",
        "# from src.cnn import *\n",
        "# from src.eval.evaluate import eval_fn, accuracy\n",
        "# from src.training import train_fn\n",
        "# from src.data_augmentations import *\n",
        "\n",
        "\n",
        "data_dir ='/content/drive/My Drive/DEEP_LEARNING/DLCOMP/dataset'\n",
        "\n",
        "def main(data_dir,\n",
        "         torch_model,\n",
        "         num_epochs=10,\n",
        "         batch_size=50,\n",
        "         learning_rate=0.001,\n",
        "         train_criterion=torch.nn.CrossEntropyLoss,\n",
        "         model_optimizer=torch.optim.Adam,\n",
        "         data_augmentations=None,\n",
        "         save_model_str=None,\n",
        "         use_all_data_to_train=False,\n",
        "         exp_name=''):\n",
        "    \"\"\"\n",
        "    Training loop for configurableNet.\n",
        "    :param data_dir: dataset path (str)\n",
        "    :param num_epochs: (int)\n",
        "    :param batch_size: (int)\n",
        "    :param learning_rate: model optimizer learning rate (float)\n",
        "    :param train_criterion: Which loss to use during training (torch.nn._Loss)\n",
        "    :param model_optimizer: Which model optimizer to use during trainnig (torch.optim.Optimizer)\n",
        "    :param data_augmentations: List of data augmentations to apply such as rescaling.\n",
        "        (list[transformations], transforms.Composition[list[transformations]], None)\n",
        "        If none only ToTensor is used\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    # Device configuration\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    if data_augmentations is None:\n",
        "        data_augmentations = transforms.ToTensor()\n",
        "    elif isinstance(data_augmentations, list):\n",
        "        data_augmentations = transforms.Compose(data_augmentations)\n",
        "    elif not isinstance(data_augmentations, transforms.Compose):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    # Load the dataset\n",
        "    train_data = ImageFolder(os.path.join(data_dir, 'train'), transform=data_augmentations)\n",
        "    val_data = ImageFolder(os.path.join(data_dir, 'val'), transform=data_augmentations)\n",
        "    test_data = ImageFolder(os.path.join(data_dir, 'test'), transform=data_augmentations)\n",
        "\n",
        "    channels, img_height, img_width = train_data[0][0].shape\n",
        "\n",
        "    # image size\n",
        "    input_shape = (channels, img_height, img_width)\n",
        "\n",
        "    # instantiate training criterion\n",
        "    train_criterion = train_criterion().to(device)\n",
        "    score = []\n",
        "\n",
        "    if use_all_data_to_train:\n",
        "        train_loader = DataLoader(dataset=ConcatDataset([train_data, val_data, test_data]),\n",
        "                                  batch_size=batch_size,\n",
        "                                  shuffle=True)\n",
        "        logging.warning('Training with all the data (train, val and test).')\n",
        "    else:\n",
        "        train_loader = DataLoader(dataset=train_data,\n",
        "                                  batch_size=batch_size,\n",
        "                                  shuffle=True)\n",
        "        val_loader = DataLoader(dataset=val_data,\n",
        "                                 batch_size=batch_size,\n",
        "                                 shuffle=False)\n",
        "\n",
        "    model = torch_model(input_shape=input_shape,\n",
        "                        num_classes=len(train_data.classes)).to(device)\n",
        "\n",
        "    # instantiate optimizer\n",
        "    optimizer = model_optimizer(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Info about the model being trained\n",
        "    # You can find the number of learnable parameters in the model here\n",
        "    logging.info('Model being trained:')\n",
        "    summary(model, input_shape,\n",
        "            device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Train the model\n",
        "    for epoch in range(num_epochs):\n",
        "        logging.info('#' * 50)\n",
        "        logging.info('Epoch [{}/{}]'.format(epoch + 1, num_epochs))\n",
        "\n",
        "        train_score, train_loss = train_fn(model, optimizer, train_criterion, train_loader, device)\n",
        "        logging.info('Train accuracy: %f', train_score)\n",
        "\n",
        "        if not use_all_data_to_train:\n",
        "            test_score = eval_fn(model, val_loader, device)\n",
        "            logging.info('Validation accuracy: %f', test_score)\n",
        "            score.append(test_score)\n",
        "\n",
        "    if save_model_str:\n",
        "        # Save the model checkpoint can be restored via \"model = torch.load(save_model_str)\"\n",
        "        model_save_dir = os.path.join(os.getcwd(), save_model_str)\n",
        "\n",
        "        if not os.path.exists(model_save_dir):\n",
        "            os.mkdir(model_save_dir)\n",
        "\n",
        "        save_model_str = os.path.join(model_save_dir, exp_name + '_model_' + str(int(time.time())))\n",
        "        torch.save(model.state_dict(), save_model_str)\n",
        "\n",
        "    if not use_all_data_to_train:\n",
        "        logging.info('Accuracy at each epoch: ' + str(score))\n",
        "        logging.info('Mean of accuracies across all epochs: ' + str(100*np.mean(score))+'%')\n",
        "        logging.info('Accuracy of model at final epoch: ' + str(100*score[-1])+'%')\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    \"\"\"\n",
        "    This is just an example of a training pipeline.\n",
        "\n",
        "    Feel free to add or remove more arguments, change default values or hardcode parameters to use.\n",
        "    \"\"\"\n",
        "    loss_dict = {'cross_entropy': torch.nn.CrossEntropyLoss} # Feel free to add more\n",
        "    opti_dict = {'sgd': torch.optim.SGD, 'adam': torch.optim.Adam} # Feel free to add more\n",
        "\n",
        "    cmdline_parser = argparse.ArgumentParser('DL WS20/21 Competition')\n",
        "\n",
        "    cmdline_parser.add_argument('-m', '--model',\n",
        "                                default='SampleModel',\n",
        "                                help='Class name of model to train',\n",
        "                                type=str)\n",
        "    cmdline_parser.add_argument('-e', '--epochs',\n",
        "                                default=50,\n",
        "                                help='Number of epochs',\n",
        "                                type=int)\n",
        "    cmdline_parser.add_argument('-b', '--batch_size',\n",
        "                                default=282,\n",
        "                                help='Batch size',\n",
        "                                type=int)\n",
        "    # cmdline_parser.add_argument('-D', '--data_dir',\n",
        "    #                             default=os.path.join(os.path.dirname(os.path.abspath(__file__)),\n",
        "    #                                                  '..', 'dataset'),\n",
        "    #                             help='Directory in which the data is stored (can be downloaded)')\n",
        "    cmdline_parser.add_argument('-l', '--learning_rate',\n",
        "                                default=2.244958736283895e-05,\n",
        "                                help='Optimizer learning rate',\n",
        "                                type=float)\n",
        "    cmdline_parser.add_argument('-L', '--training_loss',\n",
        "                                default='cross_entropy',\n",
        "                                help='Which loss to use during training',\n",
        "                                choices=list(loss_dict.keys()),\n",
        "                                type=str)\n",
        "    cmdline_parser.add_argument('-o', '--optimizer',\n",
        "                                default='adam',\n",
        "                                help='Which optimizer to use during training',\n",
        "                                choices=list(opti_dict.keys()),\n",
        "                                type=str)\n",
        "    cmdline_parser.add_argument('-p', '--model_path',\n",
        "                                default='models',\n",
        "                                help='Path to store model',\n",
        "                                type=str)\n",
        "    cmdline_parser.add_argument('-v', '--verbose',\n",
        "                                default='INFO',\n",
        "                                choices=['INFO', 'DEBUG'],\n",
        "                                help='verbosity')\n",
        "    cmdline_parser.add_argument('-n', '--exp_name',\n",
        "                                default='default',\n",
        "                                help='Name of this experiment',\n",
        "                                type=str)\n",
        "    cmdline_parser.add_argument('-d', '--data-augmentation',\n",
        "                                default='resize_and_colour_jitter',\n",
        "                                help='Data augmentation to apply to data before passing to the model.'\n",
        "                                + 'Must be available in data_augmentations.py')\n",
        "    cmdline_parser.add_argument('-a', '--use-all-data-to-train',\n",
        "                                action='store_true',\n",
        "                                help='Uses the train, validation, and test data to train the model if enabled.')\n",
        "\n",
        "    args, unknowns = cmdline_parser.parse_known_args()\n",
        "    log_lvl = logging.INFO if args.verbose == 'INFO' else logging.DEBUG\n",
        "    logging.basicConfig(level=log_lvl)\n",
        "\n",
        "    if unknowns:\n",
        "        logging.warning('Found unknown arguments!')\n",
        "        logging.warning(str(unknowns))\n",
        "        logging.warning('These will be ignored')\n",
        "\n",
        "    main(\n",
        "        data_dir=data_dir,\n",
        "        torch_model=eval(args.model),\n",
        "        num_epochs=args.epochs,\n",
        "        batch_size=args.batch_size,\n",
        "        learning_rate=args.learning_rate,\n",
        "        train_criterion=loss_dict[args.training_loss],\n",
        "        model_optimizer=opti_dict[args.optimizer],\n",
        "        data_augmentations=eval(args.data_augmentation),  # Check data_augmentations.py for sample augmentations\n",
        "        save_model_str=args.model_path,\n",
        "        exp_name=args.exp_name,\n",
        "        use_all_data_to_train=args.use_all_data_to_train\n",
        "    )\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Found unknown arguments!\n",
            "WARNING:root:['-f', '/root/.local/share/jupyter/runtime/kernel-a5e1d92a-7034-48df-aad5-430e8a8415aa.json']\n",
            "WARNING:root:These will be ignored\n",
            "INFO:root:Model being trained:\n",
            "INFO:root:##################################################\n",
            "INFO:root:Epoch [1/50]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 10, 64, 64]             280\n",
            "         MaxPool2d-2           [-1, 10, 31, 31]               0\n",
            "            Conv2d-3           [-1, 20, 31, 31]           1,820\n",
            "         MaxPool2d-4           [-1, 20, 15, 15]               0\n",
            "            Linear-5                   [-1, 32]         144,032\n",
            "            Linear-6                   [-1, 10]             330\n",
            "================================================================\n",
            "Total params: 146,462\n",
            "Trainable params: 146,462\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 0.57\n",
            "Params size (MB): 0.56\n",
            "Estimated Total Size (MB): 1.17\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-4b8ce66a0832>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0msave_model_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mexp_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0muse_all_data_to_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_all_data_to_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m     )\n",
            "\u001b[0;32m<ipython-input-25-4b8ce66a0832>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(data_dir, torch_model, num_epochs, batch_size, learning_rate, train_criterion, model_optimizer, data_augmentations, save_model_str, use_all_data_to_train, exp_name)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch [{}/{}]'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mtrain_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train accuracy: %f'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-fe27bb5e8eaa>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(model, optimizer, criterion, loader, device, train)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[1;32m    150\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2816\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2818\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2820\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdsrlvC05q1Y"
      },
      "source": [
        "training.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZeDOCOo5pbW"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# commented for notebook\n",
        "# from src.eval.evaluate import AverageMeter, accuracy\n",
        "\n",
        "def train_fn(model, optimizer, criterion, loader, device, train=True):\n",
        "    \"\"\"\n",
        "  Training method\n",
        "  :param model: model to train\n",
        "  :param optimizer: optimization algorithm\n",
        "  :criterion: loss function\n",
        "  :param loader: data loader for either training or testing set\n",
        "  :param device: torch device\n",
        "  :param train: boolean to indicate if training or test set is used\n",
        "  :return: (accuracy, loss) on the data\n",
        "  \"\"\"\n",
        "    time_begin = time.time()\n",
        "    score = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    model.train()\n",
        "    time_train = 0\n",
        "\n",
        "    t = tqdm(loader)\n",
        "    for images, labels in t:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        acc = accuracy(logits, labels)\n",
        "        n = images.size(0)\n",
        "        losses.update(loss.item(), n)\n",
        "        score.update(acc.item(), n)\n",
        "\n",
        "        t.set_description('(=> Training) Loss: {:.4f}'.format(losses.avg))\n",
        "\n",
        "    time_train += time.time() - time_begin\n",
        "    print('training time: ' + str(time_train))\n",
        "    return score.avg, losses.avg"
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}